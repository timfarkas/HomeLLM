import dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.memory import ChatMessageHistory
import time
import signal
import sys
import logging



logger = logging.getLogger("HomeLLM")
logging.basicConfig(level=logging.INFO, stream=sys.stdout, force=True)


def initializeModel(model="gpt-3.5-turbo-1106", temperature=0.2):
    """
    Initializes the chat model with the specified parameters.

    Args:
        model (str): The identifier for the OpenAI model to be used.
        temperature (float): The sampling temperature to use for generating responses.

    Returns:
        ChatOpenAI: An instance of the ChatOpenAI class initialized with the given model and temperature.
    """
    dotenv.load_dotenv()    
    chat = ChatOpenAI(model=model, temperature=temperature)
    return chat

def initializeChatHistory(systemPrompt="You are 'Aurea'. You are an AI roommate in the living room of the Aurea Berlin group/hacker house. When awoken, ask 'Hi, what's up?'. Within conversation, aim to provide deep, truthful, and intelligent replies and do not hesitate to go into sufficient amount of technical detail, Aureans are smart and will understand.", messages=[], chat=None, generateInitialMessage=False):
    """
    Initializes the chat history with a system prompt and any previous messages.

    Args:
        systemPrompt (str): The initial prompt that sets the context for the AI.
        messages (list): A list of previous messages to be included in the chat history.
        chat (ChatOpenAI): The chat model instance to use for generating initial messages.
        generateInitialMessage (bool): Flag to determine if an initial message should be generated by the AI.

    Returns:
        ChatMessageHistory: An instance of ChatMessageHistory with the system prompt and messages added.

    Raises:
        ValueError: If no system prompt is provided or if generateInitialMessage is True but no chat model is provided.
    """
    if systemPrompt is None:
        raise ValueError("No system prompt provided")
    chat_history = ChatMessageHistory()
    chat_history.add_message(SystemMessage(content=systemPrompt))
    for msg in messages:
        chat_history.add_message(msg)
    if generateInitialMessage:
        if chat is None:
            raise ValueError("No chat model provided, provide chat argument or set generateInitialMessage to False.")
        reply = chat.invoke(chat_history.messages)
        chat_history.add_ai_message(reply)
    return chat_history

def sendMessage(chat, chat_history, message=None):
    """
    Sends a message to the chat model and updates the chat history with the response.

    Args:
        chat (ChatOpenAI): The chat model instance to use for sending the message.
        chat_history (ChatMessageHistory): The current chat history to which the message and response will be added.
        message (str): The message to send to the chat model.

    Returns:
        tuple: A tuple containing the AI's response and the updated chat history.

    Raises:
        ValueError: If no message is provided.
    """
    if message is None:
        raise ValueError("No message provided")
    chat_history.add_message(HumanMessage(content=message))
    reply = chat.invoke(chat_history.messages)
    chat_history.add_message(reply)
    return reply, chat_history

def timeoutHandler(signum, frame):
    """
    Signal handler for input timeouts.

    Args:
        signum (int): The signal number.
        frame (frame): The current stack frame.

    Raises:
        Exception: An exception indicating that the time for input has expired.
    """
    raise Exception("Time for input has expired")

def outputMessage(message, speaker="Aurea"):
    """
    Outputs a message to the console, potentially with a speaker's name.

    Args:
        message (SystemMessage): The message object containing the content to be printed.
        speaker (str): The name of the speaker to be prefixed to the message.

    Note:
        This function is to be expanded to allow voice functionality.
    """
    print(speaker + ": " + message.content)

def gatherInputMessage():
    """
    Gathers an input message string from the user.

    Returns:
        str: The input message string provided by the user.

    Note:
        This function is to be expanded to allow voice functionality.
    """
    input_message = input("Enter your message: ")
    return input_message

def loopConversation(chat, initialMessage="", breakTimeThreshold=5, verbose=False, logger=logger):
    """
    Loops the conversation between the user and the AI until a timeout occurs.

    Args:
        chat (ChatOpenAI): The chat model instance to use for the conversation.
        initialMessage (str): An optional initial message to start the conversation.
        breakTimeThreshold (int): The time in seconds before the conversation loop times out due to inactivity.
        verbose (bool): If True, logs additional information.
        logger (logging.Logger): The logger instance to use for logging.

    Note:
        The conversation loop can be exited by a timeout.
    """
    messages = []
    if initialMessage:
        messages = [HumanMessage(content=initialMessage)]
    history = initializeChatHistory(messages=messages, chat=chat, generateInitialMessage=True)
    outputMessage(history.messages.pop())
    while True:
        signal.signal(signal.SIGALRM, timeoutHandler)
        signal.alarm(breakTimeThreshold)
        try:
            newMsg = gatherInputMessage()
        except Exception as e:
            if verbose:
                logger.log(msg="Exiting due to timeout.", level=logging.INFO)
            break
        finally:
            signal.alarm(0)  # Disable the alarm

        reply, history = sendMessage(chat, history, newMsg)
        outputMessage(reply)